{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8ef795b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import debugger\n",
    "import pdb\n",
    "\n",
    "import re\n",
    "\n",
    "# selenium\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "\n",
    "\n",
    "# BeautifulSoup\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "# add time\n",
    "import time\n",
    "\n",
    "#to send keys from keyboard\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "\n",
    "from selenium.webdriver.common.alert import Alert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "092ce12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_url(url):\n",
    "    \"\"\"function to open the entered url in browser\"\"\"\n",
    "    global driver\n",
    "    # first, connect to the webdriver\n",
    "    driver=webdriver.Chrome(r\"C:\\Users\\princ\\Downloads\\chromedriver_win32 (3)\\chromedriver.exe\")\n",
    "    driver.get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92cf9f53",
   "metadata": {},
   "source": [
    "# 1. Scrape the details of most viewed videos on YouTube from Wikipedia:\n",
    "Url = https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos/\n",
    "You need to find following details:\n",
    "A) Rank\n",
    "B) Name\n",
    "C) Artist\n",
    "D) Upload date\n",
    "E) Views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "186a2b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.common.by import By"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "26654d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "Url ='https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c8e2fc6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\princ\\AppData\\Local\\Temp/ipykernel_9900/1434690820.py:5: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver=webdriver.Chrome(r\"C:\\Users\\princ\\Downloads\\chromedriver_win32 (3)\\chromedriver.exe\")\n"
     ]
    }
   ],
   "source": [
    "open_url(Url)\n",
    "\n",
    "# get webelements for all 30 rows\n",
    "top30_rows_wbe=driver.find_elements(By.XPATH,\"//table[@class='wikitable sortable jquery-tablesorter']//following::tbody\")\n",
    "# get webelement for table with top 30 YT videos list\n",
    "# store all text in a list\n",
    "for i in top30_rows_wbe:\n",
    "    temp_text=i.text\n",
    "    break # exit after first iteration\n",
    "    \n",
    "sep_rows=temp_text.split('\\n')\n",
    "\n",
    "rank=[]\n",
    "rank.clear()\n",
    "vid_name=[]\n",
    "vid_name.clear()\n",
    "artist=[]\n",
    "artist.clear()\n",
    "views=[]\n",
    "views.clear()\n",
    "date=[]\n",
    "date.clear()\n",
    "\n",
    "for i in sep_rows:\n",
    "    \n",
    "    rank.append(i.split('.')[0])\n",
    "    \n",
    "    vid_name.append(i.split('[')[0].split('.')[-1].strip())\n",
    "    \n",
    "    artist.append(re.split('\\d+',i.split(']')[1])[0])\n",
    "    \n",
    "    views.append(str(re.compile('\\d+').findall(i.split(']')[1])[0])+'.'+str(re.compile('\\d+').findall(i.split(']')[1])[1]))\n",
    "    \n",
    "    date.append(str(re.compile('[a-zA-Z]+\\s+\\d{2}').findall(i.split('.')[2]))+','+str(re.compile('\\d{4}').findall(i.split('.')[2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a9ffd053",
   "metadata": {},
   "outputs": [],
   "source": [
    "top30_vid=pd.DataFrame({})\n",
    "top30_vid['Rank']=rank\n",
    "top30_vid['Name']=vid_name\n",
    "top30_vid['Artist']=artist\n",
    "top30_vid['Views (in billions)']=views\n",
    "top30_vid['Release Date']=date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "84667bd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Name</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Views (in billions)</th>\n",
       "      <th>Release Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>\"Baby Shark Dance\"</td>\n",
       "      <td>Pinkfong Baby Shark - Kids' Songs &amp; Stories</td>\n",
       "      <td>11.40</td>\n",
       "      <td>['June 17'],['2016']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>\"Despacito\"</td>\n",
       "      <td>Luis Fonsi</td>\n",
       "      <td>7.98</td>\n",
       "      <td>['January 12'],['2017']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>\"Johny Johny Yes Papa\"</td>\n",
       "      <td>LooLoo Kids</td>\n",
       "      <td>6.47</td>\n",
       "      <td>[],['2016']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>\"Shape of You\"</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>5.81</td>\n",
       "      <td>['January 30'],['2017']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>\"See You Again\"</td>\n",
       "      <td>Wiz Khalifa</td>\n",
       "      <td>5.64</td>\n",
       "      <td>[],['2015']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>\"Bath Song\"</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>5.63</td>\n",
       "      <td>[],['2018']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>\"Phonics Song with Two Words\"</td>\n",
       "      <td>ChuChu TV</td>\n",
       "      <td>4.90</td>\n",
       "      <td>[],['2014']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>\"Uptown Funk\"</td>\n",
       "      <td>Mark Ronson</td>\n",
       "      <td>4.70</td>\n",
       "      <td>['November 19'],['2014']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>\"Learning Colors – Colorful Eggs on a Farm\"</td>\n",
       "      <td>Miroshka TV</td>\n",
       "      <td>4.65</td>\n",
       "      <td>['February 27'],['2018']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>\"Gangnam Style\"</td>\n",
       "      <td>Psy</td>\n",
       "      <td>4.55</td>\n",
       "      <td>['July 15'],['2012']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>\"Masha and the Bear – Recipe for Disaster\"</td>\n",
       "      <td>Get Movies</td>\n",
       "      <td>4.51</td>\n",
       "      <td>['January 31'],['2012']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>\"Wheels on the Bus\"</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>4.40</td>\n",
       "      <td>['May 24'],['2018']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>\"Dame Tu Cosita\"</td>\n",
       "      <td>El Chombo</td>\n",
       "      <td>4.07</td>\n",
       "      <td>[],['2018']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>\"Sugar\"</td>\n",
       "      <td>Maroon</td>\n",
       "      <td>5.3</td>\n",
       "      <td>['January 14'],['2015']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>\"Roar\"</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>3.66</td>\n",
       "      <td>[],['2013']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>\"Counting Stars\"</td>\n",
       "      <td>OneRepublic</td>\n",
       "      <td>3.65</td>\n",
       "      <td>['May 31'],['2013']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>\"Sorry\"</td>\n",
       "      <td>Justin Bieber</td>\n",
       "      <td>3.59</td>\n",
       "      <td>['October 22'],['2015']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>\"Axel F\"</td>\n",
       "      <td>Crazy Frog</td>\n",
       "      <td>3.52</td>\n",
       "      <td>['June 16'],['2009']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>\"Thinking Out Loud\"</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>3.50</td>\n",
       "      <td>[],['2014']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>\"Baa Baa Black Sheep\"</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>3.38</td>\n",
       "      <td>['June 25'],['2018']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>\"Dark Horse\"</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>3.35</td>\n",
       "      <td>['February 20'],['2014']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>\"Faded\"</td>\n",
       "      <td>Alan Walker</td>\n",
       "      <td>3.34</td>\n",
       "      <td>[],['2015']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>\"Girls Like You\"</td>\n",
       "      <td>Maroon</td>\n",
       "      <td>5.3</td>\n",
       "      <td>['May 31'],['2018']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>\"Let Her Go\"</td>\n",
       "      <td>Passenger</td>\n",
       "      <td>3.30</td>\n",
       "      <td>['July 25'],['2012']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>\"Bailando\"</td>\n",
       "      <td>Enrique Iglesias</td>\n",
       "      <td>3.27</td>\n",
       "      <td>['April 11'],['2014']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>\"Lean On\"</td>\n",
       "      <td>Major Lazer</td>\n",
       "      <td>3.26</td>\n",
       "      <td>['March 22'],['2015']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>\"Perfect\"</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>3.26</td>\n",
       "      <td>[],['2017']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>\"Waka Waka (This Time for Africa)\"</td>\n",
       "      <td>Shakira</td>\n",
       "      <td>3.25</td>\n",
       "      <td>[],['2010']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>\"Shake It Off\"</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>3.21</td>\n",
       "      <td>['August 18'],['2014']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>\"Humpty the train on a fruits ride\"</td>\n",
       "      <td>Kiddiestv Hindi – Nursery Rhymes &amp; Kids Songs</td>\n",
       "      <td>3.17</td>\n",
       "      <td>['January 26'],['2018']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                                         Name  \\\n",
       "0     1                           \"Baby Shark Dance\"   \n",
       "1     2                                  \"Despacito\"   \n",
       "2     3                       \"Johny Johny Yes Papa\"   \n",
       "3     4                               \"Shape of You\"   \n",
       "4     5                              \"See You Again\"   \n",
       "5     6                                  \"Bath Song\"   \n",
       "6     7                \"Phonics Song with Two Words\"   \n",
       "7     8                                \"Uptown Funk\"   \n",
       "8     9  \"Learning Colors – Colorful Eggs on a Farm\"   \n",
       "9    10                              \"Gangnam Style\"   \n",
       "10   11   \"Masha and the Bear – Recipe for Disaster\"   \n",
       "11   12                          \"Wheels on the Bus\"   \n",
       "12   13                             \"Dame Tu Cosita\"   \n",
       "13   14                                      \"Sugar\"   \n",
       "14   15                                       \"Roar\"   \n",
       "15   16                             \"Counting Stars\"   \n",
       "16   17                                      \"Sorry\"   \n",
       "17   18                                     \"Axel F\"   \n",
       "18   18                          \"Thinking Out Loud\"   \n",
       "19   20                        \"Baa Baa Black Sheep\"   \n",
       "20   21                                 \"Dark Horse\"   \n",
       "21   22                                      \"Faded\"   \n",
       "22   23                             \"Girls Like You\"   \n",
       "23   24                                 \"Let Her Go\"   \n",
       "24   25                                   \"Bailando\"   \n",
       "25   26                                    \"Lean On\"   \n",
       "26   27                                    \"Perfect\"   \n",
       "27   28           \"Waka Waka (This Time for Africa)\"   \n",
       "28   29                               \"Shake It Off\"   \n",
       "29   30          \"Humpty the train on a fruits ride\"   \n",
       "\n",
       "                                             Artist Views (in billions)  \\\n",
       "0      Pinkfong Baby Shark - Kids' Songs & Stories                11.40   \n",
       "1                                       Luis Fonsi                 7.98   \n",
       "2                                      LooLoo Kids                 6.47   \n",
       "3                                       Ed Sheeran                 5.81   \n",
       "4                                      Wiz Khalifa                 5.64   \n",
       "5                       Cocomelon – Nursery Rhymes                 5.63   \n",
       "6                                        ChuChu TV                 4.90   \n",
       "7                                      Mark Ronson                 4.70   \n",
       "8                                      Miroshka TV                 4.65   \n",
       "9                                              Psy                 4.55   \n",
       "10                                      Get Movies                 4.51   \n",
       "11                      Cocomelon – Nursery Rhymes                 4.40   \n",
       "12                                       El Chombo                 4.07   \n",
       "13                                          Maroon                  5.3   \n",
       "14                                      Katy Perry                 3.66   \n",
       "15                                     OneRepublic                 3.65   \n",
       "16                                   Justin Bieber                 3.59   \n",
       "17                                      Crazy Frog                 3.52   \n",
       "18                                      Ed Sheeran                 3.50   \n",
       "19                      Cocomelon – Nursery Rhymes                 3.38   \n",
       "20                                      Katy Perry                 3.35   \n",
       "21                                     Alan Walker                 3.34   \n",
       "22                                          Maroon                  5.3   \n",
       "23                                       Passenger                 3.30   \n",
       "24                                Enrique Iglesias                 3.27   \n",
       "25                                     Major Lazer                 3.26   \n",
       "26                                      Ed Sheeran                 3.26   \n",
       "27                                         Shakira                 3.25   \n",
       "28                                    Taylor Swift                 3.21   \n",
       "29   Kiddiestv Hindi – Nursery Rhymes & Kids Songs                 3.17   \n",
       "\n",
       "                Release Date  \n",
       "0       ['June 17'],['2016']  \n",
       "1    ['January 12'],['2017']  \n",
       "2                [],['2016']  \n",
       "3    ['January 30'],['2017']  \n",
       "4                [],['2015']  \n",
       "5                [],['2018']  \n",
       "6                [],['2014']  \n",
       "7   ['November 19'],['2014']  \n",
       "8   ['February 27'],['2018']  \n",
       "9       ['July 15'],['2012']  \n",
       "10   ['January 31'],['2012']  \n",
       "11       ['May 24'],['2018']  \n",
       "12               [],['2018']  \n",
       "13   ['January 14'],['2015']  \n",
       "14               [],['2013']  \n",
       "15       ['May 31'],['2013']  \n",
       "16   ['October 22'],['2015']  \n",
       "17      ['June 16'],['2009']  \n",
       "18               [],['2014']  \n",
       "19      ['June 25'],['2018']  \n",
       "20  ['February 20'],['2014']  \n",
       "21               [],['2015']  \n",
       "22       ['May 31'],['2018']  \n",
       "23      ['July 25'],['2012']  \n",
       "24     ['April 11'],['2014']  \n",
       "25     ['March 22'],['2015']  \n",
       "26               [],['2017']  \n",
       "27               [],['2010']  \n",
       "28    ['August 18'],['2014']  \n",
       "29   ['January 26'],['2018']  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top30_vid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e6e9c4",
   "metadata": {},
   "source": [
    "# 2. Scrape the details team India’s international fixtures from bcci.tv.\n",
    "Url = https://www.bcci.tv/.\n",
    "You need to find following details:\n",
    "A) Match title (I.e. 1st ODI)\n",
    "B) Series\n",
    "C) Place\n",
    "D) Date\n",
    "E) Time\n",
    "Note: - From bcci.tv home page you have reach to the international fixture page through code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c08c41f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\princ\\AppData\\Local\\Temp/ipykernel_9900/1434690820.py:5: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver=webdriver.Chrome(r\"C:\\Users\\princ\\Downloads\\chromedriver_win32 (3)\\chromedriver.exe\")\n"
     ]
    },
    {
     "ename": "NoSuchElementException",
     "evalue": "Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"//li[@data-nav-index='0']\"}\n  (Session info: chrome=106.0.5249.103)\nStacktrace:\nBacktrace:\n\tOrdinal0 [0x00AADF13+2219795]\n\tOrdinal0 [0x00A42841+1779777]\n\tOrdinal0 [0x0095423D+803389]\n\tOrdinal0 [0x00983025+995365]\n\tOrdinal0 [0x009831EB+995819]\n\tOrdinal0 [0x009B0F52+1183570]\n\tOrdinal0 [0x0099E844+1108036]\n\tOrdinal0 [0x009AF192+1175954]\n\tOrdinal0 [0x0099E616+1107478]\n\tOrdinal0 [0x00977F89+950153]\n\tOrdinal0 [0x00978F56+954198]\n\tGetHandleVerifier [0x00DA2CB2+3040210]\n\tGetHandleVerifier [0x00D92BB4+2974420]\n\tGetHandleVerifier [0x00B46A0A+565546]\n\tGetHandleVerifier [0x00B45680+560544]\n\tOrdinal0 [0x00A49A5C+1808988]\n\tOrdinal0 [0x00A4E3A8+1827752]\n\tOrdinal0 [0x00A4E495+1827989]\n\tOrdinal0 [0x00A580A4+1867940]\n\tBaseThreadInitThunk [0x769A6739+25]\n\tRtlGetFullPathName_UEx [0x77DA8FD2+1218]\n\tRtlGetFullPathName_UEx [0x77DA8F9D+1165]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNoSuchElementException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9900/3466085588.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# click on \"International\" button to expand it\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mXPATH\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"//li[@data-nav-index='0']\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclick\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# click on 'Fixtures'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mfind_element\u001b[1;34m(self, by, value)\u001b[0m\n\u001b[0;32m    853\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'[name=\"%s\"]'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    854\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 855\u001b[1;33m         return self.execute(Command.FIND_ELEMENT, {\n\u001b[0m\u001b[0;32m    856\u001b[0m             \u001b[1;34m'using'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    857\u001b[0m             'value': value})['value']\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    426\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    427\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 428\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    429\u001b[0m             response['value'] = self._unwrap_value(\n\u001b[0;32m    430\u001b[0m                 response.get('value', None))\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    241\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'alert'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    242\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 243\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNoSuchElementException\u001b[0m: Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"//li[@data-nav-index='0']\"}\n  (Session info: chrome=106.0.5249.103)\nStacktrace:\nBacktrace:\n\tOrdinal0 [0x00AADF13+2219795]\n\tOrdinal0 [0x00A42841+1779777]\n\tOrdinal0 [0x0095423D+803389]\n\tOrdinal0 [0x00983025+995365]\n\tOrdinal0 [0x009831EB+995819]\n\tOrdinal0 [0x009B0F52+1183570]\n\tOrdinal0 [0x0099E844+1108036]\n\tOrdinal0 [0x009AF192+1175954]\n\tOrdinal0 [0x0099E616+1107478]\n\tOrdinal0 [0x00977F89+950153]\n\tOrdinal0 [0x00978F56+954198]\n\tGetHandleVerifier [0x00DA2CB2+3040210]\n\tGetHandleVerifier [0x00D92BB4+2974420]\n\tGetHandleVerifier [0x00B46A0A+565546]\n\tGetHandleVerifier [0x00B45680+560544]\n\tOrdinal0 [0x00A49A5C+1808988]\n\tOrdinal0 [0x00A4E3A8+1827752]\n\tOrdinal0 [0x00A4E495+1827989]\n\tOrdinal0 [0x00A580A4+1867940]\n\tBaseThreadInitThunk [0x769A6739+25]\n\tRtlGetFullPathName_UEx [0x77DA8FD2+1218]\n\tRtlGetFullPathName_UEx [0x77DA8F9D+1165]\n"
     ]
    }
   ],
   "source": [
    "open_url('https://www.bcci.tv')\n",
    "\n",
    "time.sleep(5)\n",
    "\n",
    "# click on \"International\" button to expand it\n",
    "driver.find_element(By.XPATH,\"/html/body/nav/div[1]/div[2]/ul[1]/li[2]/a\").click()\n",
    "\n",
    "# click on 'Fixtures'\n",
    "driver.find_element(By.XPATH,\"//li[@data-nav-index='0']//following::a[@href='/international/fixtures']\").click()\n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "# store webelements for all series names\n",
    "series_wbe=driver.find_elements(By.XPATH,\"//div[@class='fixture__format-strip']/span\")\n",
    "\n",
    "fixture_frame_text=[]\n",
    "\n",
    "for i in series_wbe:\n",
    "    fixture_frame_text.append(i.text)\n",
    "    \n",
    "fixture_name=[]\n",
    "fixture_name.clear()\n",
    "fixture_type=[]\n",
    "fixture_type.clear()\n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "for i in range(len(fixture_frame_text)):\n",
    "    if i%2!=0:\n",
    "        fixture_name.append(fixture_frame_text[i])\n",
    "    else:\n",
    "        fixture_type.append(fixture_frame_text[i])\n",
    "\n",
    "# get webelment for match title\n",
    "title_wbe=driver.find_elements(By.XPATH,\"//p[@class='fixture__additional-info']\")\n",
    "\n",
    "title=[]\n",
    "title.clear()\n",
    "loc=[]\n",
    "loc.clear()\n",
    "\n",
    "for i in title_wbe:\n",
    "    title.append(i.text.split('\\n')[0])\n",
    "    loc.append(i.text.split('\\n')[1])\n",
    "    \n",
    "#get webelement for date and time\n",
    "try:\n",
    "    date_wbe=driver.find_elements(bY.xpath,\"//div[@class='fixture__datetime desktop-only']\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "date=[]\n",
    "date.clear()\n",
    "time=[]\n",
    "time.clear()\n",
    "\n",
    "for i in date_wbe:\n",
    "#     pdb.set_trace()\n",
    "    date.append(str(i.text.split('\\n')[0])+str('-')+str(i.text.split('\\n')[1]+str('th')+str(i.text.split('\\n')[2])))\n",
    "    time.append(i.text.split('\\n')[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fee1004b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fixture_name' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9900/364089925.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mind_fixture\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mind_fixture\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Tournament'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfixture_name\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mind_fixture\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Fixture'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfixture_type\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mind_fixture\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Match'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mind_fixture\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Venue'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'fixture_name' is not defined"
     ]
    }
   ],
   "source": [
    "ind_fixture=pd.DataFrame({})\n",
    "ind_fixture['Tournament']=fixture_name\n",
    "ind_fixture['Fixture']=fixture_type\n",
    "ind_fixture['Match']=title\n",
    "ind_fixture['Venue']=loc\n",
    "ind_fixture['Date']=date\n",
    "ind_fixture['Time']=time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bf9a2c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f137fc",
   "metadata": {},
   "source": [
    "# 3. Scrape the details of selenium exception from guru99.com.\n",
    "Url = https://www.guru99.com/\n",
    "You need to find following details:\n",
    "A) Name\n",
    "B) Description\n",
    "Note: - From guru99 home page you have to reach to selenium exception handling page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22b1f653",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\princ\\AppData\\Local\\Temp/ipykernel_13696/43368851.py:2: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver=webdriver.Chrome(r\"C:\\Users\\princ\\Downloads\\chromedriver_win32 (3)\\chromedriver.exe\")\n"
     ]
    }
   ],
   "source": [
    "#connecting to the web driver\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\princ\\Downloads\\chromedriver_win32 (3)\\chromedriver.exe\")\n",
    "#get the url\n",
    "url = \"https://www.guru99.com/\"\n",
    "driver.get(url)\n",
    "\n",
    "# clicking the 'selenium'\n",
    "selenium=driver.find_element(By.XPATH,\"/html/body/footer/div/div[1]/div/div/div/div/div/div/section/div/div/div[2]/div/div/div/div/div[2]/div/div/div[2]/div/div[2]/div/div/div[3]/div/div/div[2]/div/div/a/div[2]/h5\")\n",
    "selenium.click()\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "421e9980",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Google Chrome 12+\\nFirefox\\nInternet Explorer ...</td>\n",
       "      <td>Operating System</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Windows, Mac OS X, Linux</td>\n",
       "      <td>All operating systems where the browsers above...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Selenium IDE</td>\n",
       "      <td>To learn about concepts on automated testing a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Selenium RC</td>\n",
       "      <td>To design a test using a more expressive langu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WebDriver</td>\n",
       "      <td>To use a certain programming language in desig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Selenium Grid</td>\n",
       "      <td>To run your Selenium RC scripts in multiple br...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Open source, free to use, and free of charge.</td>\n",
       "      <td>Commercial.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Highly extensible</td>\n",
       "      <td>Limited add-ons</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Can run tests across different browsers</td>\n",
       "      <td>Can only run tests in Firefox, Internet Explor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Supports various operating systems</td>\n",
       "      <td>Can only be used in Windows</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Name  \\\n",
       "0  Google Chrome 12+\\nFirefox\\nInternet Explorer ...   \n",
       "1                           Windows, Mac OS X, Linux   \n",
       "2                                       Selenium IDE   \n",
       "3                                        Selenium RC   \n",
       "4                                          WebDriver   \n",
       "5                                      Selenium Grid   \n",
       "6      Open source, free to use, and free of charge.   \n",
       "7                                  Highly extensible   \n",
       "8            Can run tests across different browsers   \n",
       "9                 Supports various operating systems   \n",
       "\n",
       "                                         Description  \n",
       "0                                   Operating System  \n",
       "1  All operating systems where the browsers above...  \n",
       "2  To learn about concepts on automated testing a...  \n",
       "3  To design a test using a more expressive langu...  \n",
       "4  To use a certain programming language in desig...  \n",
       "5  To run your Selenium RC scripts in multiple br...  \n",
       "6                                        Commercial.  \n",
       "7                                    Limited add-ons  \n",
       "8  Can only run tests in Firefox, Internet Explor...  \n",
       "9                        Can only be used in Windows  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clicking the 'exception handling'\n",
    "tutorial=driver.find_element(By.XPATH,\"/html/body/div[1]/div/div/div/main/div/article/div/div/table[1]/tbody/tr[1]/td[1]/a\")\n",
    "tutorial.click()\n",
    "\n",
    "#creating empty list for scraping data\n",
    "Name=[]\n",
    "Description=[]\n",
    "\n",
    "# scraping name\n",
    "name = driver.find_elements(By.XPATH,\"//table[@class='table table-striped']//td\")\n",
    "for i in name:       \n",
    "    if i.text is None :\n",
    "        Name.append(\"--\") \n",
    "    else:\n",
    "        Name.append(i.text)\n",
    "\n",
    "# scraping Description\n",
    "desc = driver.find_elements(By.XPATH,\"//table[@class='table table-striped']//td\")\n",
    "for i in desc:       \n",
    "        if i.text is None :\n",
    "            Description.append(\"--\")\n",
    "        else:\n",
    "            Description.append(i.text)\n",
    "            \n",
    "# creating the dataframe from the scraped data\n",
    "df=pd.DataFrame({\"Name\":Name[2::2],\"Description\":Description[3::2]})\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8d7733",
   "metadata": {},
   "source": [
    "# 4. Scrape the details of State-wise GDP of India from statisticstime.com.\n",
    "Url = http://statisticstimes.com/\n",
    "You have to find following details:\n",
    "A) Rank\n",
    "B) State\n",
    "C) GSDP(18-19)\n",
    "D) GSDP(17-18)\n",
    "E) Share(2017)\n",
    "F) GDP($ billion)\n",
    "Note: - From statisticstimes home page you have to reach to economy page through cod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28b681d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b7ee1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#connecting to the web driver\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\princ\\Downloads\\chromedriver_win32 (3)\\chromedriver.exe\") \n",
    "\n",
    "#get the url\n",
    "url = \"http://statisticstimes.com/\"\n",
    "driver.get(url)\n",
    "\n",
    "# clicking the 'economy'\n",
    "economy=driver.find_element(By.XPATH,\"/html/body/div[2]/div[1]/div[2]/div[2]/button\")\n",
    "economy.click()\n",
    "\n",
    "# clicking the 'dropdown button'\n",
    "dropdown=driver.find_element(By.XPATH,\"/html/body/div[2]/div[1]/div[2]/div[2]/div/a[3]\")\n",
    "dropdown.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ff464fba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>State</th>\n",
       "      <th>GDSP_19_20</th>\n",
       "      <th>GSDP_18_19</th>\n",
       "      <th>Share_18_19</th>\n",
       "      <th>GDP_billion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>-</td>\n",
       "      <td>2,632,792</td>\n",
       "      <td>13.94%</td>\n",
       "      <td>399.921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>1,845,853</td>\n",
       "      <td>1,630,208</td>\n",
       "      <td>8.63%</td>\n",
       "      <td>247.629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>1,687,818</td>\n",
       "      <td>1,584,764</td>\n",
       "      <td>8.39%</td>\n",
       "      <td>240.726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>-</td>\n",
       "      <td>1,502,899</td>\n",
       "      <td>7.96%</td>\n",
       "      <td>228.290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>1,631,977</td>\n",
       "      <td>1,493,127</td>\n",
       "      <td>7.91%</td>\n",
       "      <td>226.806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>West Bengal</td>\n",
       "      <td>1,253,832</td>\n",
       "      <td>1,089,898</td>\n",
       "      <td>5.77%</td>\n",
       "      <td>165.556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Rajasthan</td>\n",
       "      <td>1,020,989</td>\n",
       "      <td>942,586</td>\n",
       "      <td>4.99%</td>\n",
       "      <td>143.179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>972,782</td>\n",
       "      <td>862,957</td>\n",
       "      <td>4.57%</td>\n",
       "      <td>131.083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Telangana</td>\n",
       "      <td>969,604</td>\n",
       "      <td>861,031</td>\n",
       "      <td>4.56%</td>\n",
       "      <td>130.791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Madhya Pradesh</td>\n",
       "      <td>906,672</td>\n",
       "      <td>809,592</td>\n",
       "      <td>4.29%</td>\n",
       "      <td>122.977</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Rank           State GDSP_19_20 GSDP_18_19 Share_18_19 GDP_billion\n",
       "0    1     Maharashtra          -  2,632,792      13.94%     399.921\n",
       "1    2      Tamil Nadu  1,845,853  1,630,208       8.63%     247.629\n",
       "2    3   Uttar Pradesh  1,687,818  1,584,764       8.39%     240.726\n",
       "3    4         Gujarat          -  1,502,899       7.96%     228.290\n",
       "4    5       Karnataka  1,631,977  1,493,127       7.91%     226.806\n",
       "5    6     West Bengal  1,253,832  1,089,898       5.77%     165.556\n",
       "6    7       Rajasthan  1,020,989    942,586       4.99%     143.179\n",
       "7    8  Andhra Pradesh    972,782    862,957       4.57%     131.083\n",
       "8    9       Telangana    969,604    861,031       4.56%     130.791\n",
       "9   10  Madhya Pradesh    906,672    809,592       4.29%     122.977"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clicking the 'statewise GDP of India'\n",
    "GDP_of_India=driver.find_element(By.XPATH,\"/html/body/div[2]/div[2]/div[2]/ul/li[1]/a\")\n",
    "GDP_of_India.click()\n",
    "\n",
    "#creating empty list for scraping data\n",
    "Rank=[]\n",
    "State=[]\n",
    "GDSP_19_20=[]\n",
    "GSDP_18_19=[]\n",
    "Share_18_19=[]\n",
    "GDP_billion=[]\n",
    "\n",
    "# scraping rank\n",
    "rank = driver.find_elements(By.XPATH,\"//td[@class='data1']\")[:33]\n",
    "for i in rank:       \n",
    "    if i.text is None :\n",
    "        Rank.append(\"--\") \n",
    "    else:\n",
    "        Rank.append(i.text)\n",
    "                \n",
    "# scraping state\n",
    "state = driver.find_elements(By.XPATH,\"//td[@class='name']\")[:33]\n",
    "for i in state:       \n",
    "    if i.text is None :\n",
    "        State.append(\"--\") \n",
    "    else:\n",
    "        State.append(i.text)\n",
    "                \n",
    "# scraping GSDP at current price (19-20)\n",
    "GSDP = driver.find_elements(By.XPATH,\"//td[@class='data']\")[:165]\n",
    "for i in GSDP:       \n",
    "    if i.text is None :\n",
    "        GDSP_19_20.append(\"--\") \n",
    "    else:\n",
    "        GDSP_19_20.append(i.text)\n",
    "                \n",
    "# scraping GSDP at current price (18-19)\n",
    "GSDP = driver.find_elements(By.XPATH,\"//td[@class='data sorting_1']\")[:33]\n",
    "for i in GSDP:       \n",
    "    if i.text is None :\n",
    "        GSDP_18_19.append(\"--\") \n",
    "    else:\n",
    "        GSDP_18_19.append(i.text)\n",
    "                \n",
    "# scraping Share(18-19)\n",
    "share = driver.find_elements(By.XPATH,\"//td[@class='data']\")[:165]\n",
    "for i in share:       \n",
    "    if i.text is None :\n",
    "        Share_18_19.append(\"--\") \n",
    "    else:\n",
    "        Share_18_19.append(i.text)\n",
    "                \n",
    "# scraping GDP($ billion)\n",
    "GDP = driver.find_elements(By.XPATH,\"//td[@class='data']\")[:165]\n",
    "for i in GDP:\n",
    "    if i.text is None :\n",
    "            GDP_billion.append(\"--\") \n",
    "    else:\n",
    "        GDP_billion.append(i.text)\n",
    "        \n",
    "# creating the dataframe from the scraped data\n",
    "df=pd.DataFrame({\"Rank\":Rank,\"State\":State,\"GDSP_19_20\":GDSP_19_20[::5],\"GSDP_18_19\":GSDP_18_19,\"Share_18_19\":Share_18_19[1::5],\"GDP_billion\":GDP_billion[2::5]})\n",
    "df.head(10)        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d593d58",
   "metadata": {},
   "source": [
    "# 5. Scrape the details of trending repositories on Github.com.\n",
    "Url = https://github.com/\n",
    "You have to find the following details:\n",
    "A) Repository title\n",
    "B) Repository description\n",
    "C) Contributors count\n",
    "D) Language used\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cc1559cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#connecting to the web driver\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\princ\\Downloads\\chromedriver_win32 (3)\\chromedriver.exe\") \n",
    "\n",
    "#get the url\n",
    "url = \"https://github.com/\"\n",
    "driver.get(url)\n",
    "\n",
    "# clicking the 'explore'\n",
    "explore=driver.find_element(By.XPATH,\"/html/body/div[4]/main/div[2]/div[3]/div[3]/div/div/div[1]/div/a\")\n",
    "explore.click()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "55185c27",
   "metadata": {},
   "outputs": [
    {
     "ename": "NoSuchElementException",
     "evalue": "Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"/html/body/div[1]/header/div/div[2]/nav/ul/li[4]/details/div/ul[2]/li[3]/a\"}\n  (Session info: chrome=106.0.5249.103)\nStacktrace:\nBacktrace:\n\tOrdinal0 [0x005BDF13+2219795]\n\tOrdinal0 [0x00552841+1779777]\n\tOrdinal0 [0x0046423D+803389]\n\tOrdinal0 [0x00493025+995365]\n\tOrdinal0 [0x004931EB+995819]\n\tOrdinal0 [0x004C0F52+1183570]\n\tOrdinal0 [0x004AE844+1108036]\n\tOrdinal0 [0x004BF192+1175954]\n\tOrdinal0 [0x004AE616+1107478]\n\tOrdinal0 [0x00487F89+950153]\n\tOrdinal0 [0x00488F56+954198]\n\tGetHandleVerifier [0x008B2CB2+3040210]\n\tGetHandleVerifier [0x008A2BB4+2974420]\n\tGetHandleVerifier [0x00656A0A+565546]\n\tGetHandleVerifier [0x00655680+560544]\n\tOrdinal0 [0x00559A5C+1808988]\n\tOrdinal0 [0x0055E3A8+1827752]\n\tOrdinal0 [0x0055E495+1827989]\n\tOrdinal0 [0x005680A4+1867940]\n\tBaseThreadInitThunk [0x76B46739+25]\n\tRtlGetFullPathName_UEx [0x774E8FD2+1218]\n\tRtlGetFullPathName_UEx [0x774E8F9D+1165]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNoSuchElementException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13696/2703448364.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# clicking the 'trending'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtrending\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mXPATH\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"/html/body/div[1]/header/div/div[2]/nav/ul/li[4]/details/div/ul[2]/li[3]/a\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mtrending\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclick\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#creating empty list for scraping the data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mfind_element\u001b[1;34m(self, by, value)\u001b[0m\n\u001b[0;32m    853\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'[name=\"%s\"]'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    854\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 855\u001b[1;33m         return self.execute(Command.FIND_ELEMENT, {\n\u001b[0m\u001b[0;32m    856\u001b[0m             \u001b[1;34m'using'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    857\u001b[0m             'value': value})['value']\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    426\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    427\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 428\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    429\u001b[0m             response['value'] = self._unwrap_value(\n\u001b[0;32m    430\u001b[0m                 response.get('value', None))\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    241\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'alert'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    242\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 243\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNoSuchElementException\u001b[0m: Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"/html/body/div[1]/header/div/div[2]/nav/ul/li[4]/details/div/ul[2]/li[3]/a\"}\n  (Session info: chrome=106.0.5249.103)\nStacktrace:\nBacktrace:\n\tOrdinal0 [0x005BDF13+2219795]\n\tOrdinal0 [0x00552841+1779777]\n\tOrdinal0 [0x0046423D+803389]\n\tOrdinal0 [0x00493025+995365]\n\tOrdinal0 [0x004931EB+995819]\n\tOrdinal0 [0x004C0F52+1183570]\n\tOrdinal0 [0x004AE844+1108036]\n\tOrdinal0 [0x004BF192+1175954]\n\tOrdinal0 [0x004AE616+1107478]\n\tOrdinal0 [0x00487F89+950153]\n\tOrdinal0 [0x00488F56+954198]\n\tGetHandleVerifier [0x008B2CB2+3040210]\n\tGetHandleVerifier [0x008A2BB4+2974420]\n\tGetHandleVerifier [0x00656A0A+565546]\n\tGetHandleVerifier [0x00655680+560544]\n\tOrdinal0 [0x00559A5C+1808988]\n\tOrdinal0 [0x0055E3A8+1827752]\n\tOrdinal0 [0x0055E495+1827989]\n\tOrdinal0 [0x005680A4+1867940]\n\tBaseThreadInitThunk [0x76B46739+25]\n\tRtlGetFullPathName_UEx [0x774E8FD2+1218]\n\tRtlGetFullPathName_UEx [0x774E8F9D+1165]\n"
     ]
    }
   ],
   "source": [
    "# clicking the 'trending'\n",
    "trending=driver.find_element(By.XPATH,\"/html/body/div[1]/header/div/div[2]/nav/ul/li[4]/details/div/ul[2]/li[3]/a\")\n",
    "trending.click()\n",
    "\n",
    "#creating empty list for scraping the data\n",
    "Repository_title=[]\n",
    "Repository_description=[]\n",
    "Contributors_count=[]\n",
    "Language_used=[]\n",
    "\n",
    "# scraping Repository_title\n",
    "repo_title = driver.find_elements(By.XPATH,\"//h1[@class='h3 lh-condensed']\")[:22]\n",
    "for i in repo_title:       \n",
    "    if i.text is None :\n",
    "        Repository_title.append(\"--\") \n",
    "    else:\n",
    "        Repository_title.append(i.text)\n",
    "                        \n",
    "# scraping Repository_description\n",
    "repo_desc = driver.find_elements(By.XPATH,\"//p[@class='col-9 color-text-secondary my-1 pr-4']\")[:22]\n",
    "for i in repo_desc:       \n",
    "    if i.text is None :\n",
    "        Repository_description.append(\"--\") \n",
    "    else:\n",
    "        Repository_description.append(i.text)\n",
    "            \n",
    "# scraping Language_used\n",
    "lang = driver.find_elements(By.XPATH,\"//span[@itemprop='programmingLanguage']\")\n",
    "for i in lang:       \n",
    "    if i.text is None :\n",
    "        Language_used.append(\"--\") \n",
    "    else:\n",
    "        Language_used.append(i.text)\n",
    "        \n",
    "# creating the dataframe from the scraped data\n",
    "df=pd.DataFrame({\"Repository_title\":Repository_title,\"Repository_description\":Repository_description,\"Language_used\":Language_used})\n",
    "df.head(10)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2155f51e",
   "metadata": {},
   "source": [
    "# 6. Scrape the details of top 100 songs on billiboard.com.\n",
    "Url = https:/www.billboard.com/\n",
    "You have to find the following details:\n",
    "A) Song name\n",
    "B) Artist name\n",
    "C) Last week rank\n",
    "D) Peak rank\n",
    "E) Weeks on board\n",
    "Note: - From the home page you have to click on the charts option then hot 100-page link through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4c0e59c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Song_name</th>\n",
       "      <th>Artist_name</th>\n",
       "      <th>Last_week_rank</th>\n",
       "      <th>Peak_rank</th>\n",
       "      <th>Weeks_on_board</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Song_name, Artist_name, Last_week_rank, Peak_rank, Weeks_on_board]\n",
       "Index: []"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#connecting to the web driver\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\princ\\Downloads\\chromedriver_win32 (3)\\chromedriver.exe\") \n",
    "\n",
    "#get the url\n",
    "url = \"https://www.billboard.com/\"\n",
    "driver.get(url)\n",
    "\n",
    "# clicking the chart\n",
    "chart=driver.find_element(By.XPATH,\"/html/body/div[3]/header/div/div[2]/div/div/div[2]/div[2]/div/div/nav/ul/li[1]/a\")\n",
    "chart.click()\n",
    "\n",
    "# clicking the view chart\n",
    "hot100=driver.find_element(By.XPATH,\"/html/body/div[3]/header/div/div[3]/div/nav/ul/li[1]/a\")\n",
    "hot100.click()\n",
    "\n",
    "#creating empty list for scraping data\n",
    "Song_name=[]\n",
    "Artist_name=[]\n",
    "Last_week_rank=[]\n",
    "Peak_rank=[]\n",
    "Weeks_on_board=[]\n",
    "\n",
    "# scraping Song name\n",
    "song = driver.find_elements(By.XPATH,\"//span[@class='chart-element__information__song text--truncate color--primary']\")\n",
    "for i in song:       \n",
    "    if i.text is None :\n",
    "        Song_name.append(\"--\") \n",
    "    else:\n",
    "        Song_name.append(i.text)         \n",
    "\n",
    "# scraping Artist name\n",
    "artist = driver.find_elements(By.XPATH,\"//span[@class='chart-element__information__artist text--truncate color--secondary']\")\n",
    "for i in artist:       \n",
    "    if i.text is None :\n",
    "        Artist_name.append(\"--\") \n",
    "    else:\n",
    "        Artist_name.append(i.text) \n",
    "        \n",
    "# scraping last week rank\n",
    "lw_rank = driver.find_elements(By.XPATH,\"//div[@class='chart-element__meta text--center color--secondary text--last']\")\n",
    "for i in lw_rank:       \n",
    "    if i.text is None :\n",
    "        Last_week_rank.append(\"--\") \n",
    "    else:\n",
    "        Last_week_rank.append(i.text)  \n",
    "\n",
    "# scraping peak rank\n",
    "peak = driver.find_elements(By.XPATH,\"//div[@class='chart-element__meta text--center color--secondary text--peak']\")\n",
    "for i in peak:       \n",
    "    if i.text is None :\n",
    "        Peak_rank.append(\"--\") \n",
    "    else:\n",
    "        Peak_rank.append(i.text)    \n",
    "\n",
    "# scraping Weeks_on_board\n",
    "on_board = driver.find_elements(By.XPATH,\"//div[@class='chart-element__meta text--center color--secondary text--week']\")\n",
    "for i in on_board:       \n",
    "    if i.text is None :\n",
    "        Weeks_on_board.append(\"--\")\n",
    "    else:\n",
    "        Weeks_on_board.append(i.text)\n",
    "\n",
    "# creating the dataframe from the scraped data\n",
    "df=pd.DataFrame({\"Song_name\":Song_name,\"Artist_name\":Artist_name,\"Last_week_rank\":Last_week_rank,\"Peak_rank\":Peak_rank,\"Weeks_on_board\":Weeks_on_board})\n",
    "df        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a6499f",
   "metadata": {},
   "source": [
    "# 7. Scrape the details of Data science recruiters from naukri.com.\n",
    "Url = https://www.naukri.com/\n",
    "You have to find the following details:\n",
    "A) Name\n",
    "B) Designation\n",
    "C) Company\n",
    "D) Skills they hire for\n",
    "E) Location\n",
    "Note: - From naukri.com homepage click on the recruiters option and the on the search pane type Data science and\n",
    "click on search. All this should be done through code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b703fde8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\princ\\AppData\\Local\\Temp/ipykernel_2836/1997818616.py:2: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver=webdriver.Chrome(r\"C:\\Users\\princ\\Downloads\\chromedriver_win32 (3)\\chromedriver.exe\")\n"
     ]
    }
   ],
   "source": [
    "#connecting to the web driver\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\princ\\Downloads\\chromedriver_win32 (3)\\chromedriver.exe\") \n",
    "\n",
    "#get the url\n",
    "url = \"https://www.naukri.com/hr-recruiters-consultants\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4793c1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from selenium.webdriver.common.by import By"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4db31d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# entering “Data Analyst” in “Skill,Designations,Companies” field.\n",
    "search_field=driver.find_element(By.XPATH,\"//input[@class='sugInp']\") #job search bar\n",
    "search_field.send_keys(\"Data Science\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f94f68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicking the search button\n",
    "search_button=driver.find_element(By.ID,\"qsbFormBtn\")\n",
    "search_button.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4bb6186f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating empty list for scraping data\n",
    "Name=[]\n",
    "Designation=[]\n",
    "Company=[]\n",
    "Skills_they_hire_for=[]\n",
    "Location=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a786eb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping the job-titles\n",
    "title=driver.find_elements(By.XPATH,\"//p[@class='highlightable']//a\")[:48]\n",
    "for i in title:\n",
    "    if i.text is None :\n",
    "        Name.append(\"--\") \n",
    "    else:\n",
    "        Name.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "747b11c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping the Designation\n",
    "deg=driver.find_elements(By.XPATH,\"//span[@class='ellipsis clr']\")[:48]\n",
    "for i in deg:\n",
    "    if i.text is None :\n",
    "        Designation.append(\"--\") \n",
    "    else:\n",
    "        Designation.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7b2df447",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping the Company\n",
    "comp=driver.find_elements(By.XPATH,\"//a[@class='ellipsis']\")[:48]\n",
    "for i in comp:\n",
    "    if i.text is None :\n",
    "        Company.append(\"--\") \n",
    "    else:\n",
    "        Company.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c2b8f6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping the Skills_they_hire_for\n",
    "skills=driver.find_elements(By.XPATH,\"//div[@class='hireSec highlightable']\")[:48]\n",
    "for i in skills:\n",
    "    if i.text is None :\n",
    "        Skills_they_hire_for.append(\"--\") \n",
    "    else:\n",
    "        Skills_they_hire_for.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9300225e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping the Location\n",
    "loc=driver.find_elements(By.XPATH,\"//small[@class='ellipsis']\")[:48]\n",
    "for i in loc:\n",
    "    if i.text is None :\n",
    "        Location.append(\"--\") \n",
    "    else:\n",
    "        Location.append(i.text)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f0fa2001",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Designation</th>\n",
       "      <th>Company</th>\n",
       "      <th>Skills_they_hire_for</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aakash Harit</td>\n",
       "      <td>HR Manager</td>\n",
       "      <td>Aakash Harit</td>\n",
       "      <td>Classic ASP Developer, Internet Marketing Prof...</td>\n",
       "      <td>Delhi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Science Network</td>\n",
       "      <td>Company Recruiter</td>\n",
       "      <td>Data Science Network</td>\n",
       "      <td>.Net, Java, Data Science, Linux Administration...</td>\n",
       "      <td>Hyderabad / Secunderabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>shravan Kumar Gaddam</td>\n",
       "      <td>Company HR</td>\n",
       "      <td>shravan Kumar Gaddam</td>\n",
       "      <td>Data Science, Artificial Intelligence, Machine...</td>\n",
       "      <td>Pune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Shore Infotech India Pvt. Ltd</td>\n",
       "      <td>Company Recruiter</td>\n",
       "      <td>Shore Infotech India Pvt. Ltd</td>\n",
       "      <td>Mean Stack, javascript, angularjs, mongodb, We...</td>\n",
       "      <td>Ahmedabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MARSIAN Technologies LLP</td>\n",
       "      <td>Founder CEO</td>\n",
       "      <td>MARSIAN Technologies LLP</td>\n",
       "      <td>Hadoop, Spark, Digital Strategy, Data Architec...</td>\n",
       "      <td>UK - (london)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MARSIAN Technologies LLP</td>\n",
       "      <td>Recruitment Lead Consultant</td>\n",
       "      <td>MARSIAN Technologies LLP</td>\n",
       "      <td>Analytics, Business Intelligence, Business Ana...</td>\n",
       "      <td>Vadodara / Baroda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Anik Agrawal</td>\n",
       "      <td>Programme Manager</td>\n",
       "      <td>Anik Agrawal</td>\n",
       "      <td>Data Science</td>\n",
       "      <td>Chennai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Enerlytics Software Solutions Pvt Ltd</td>\n",
       "      <td>HR Administrator</td>\n",
       "      <td>Enerlytics Software Solutions Pvt Ltd</td>\n",
       "      <td>Machine Learning, algorithms, Go Getter, Compu...</td>\n",
       "      <td>Trivandrum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>subhas patel</td>\n",
       "      <td>Director</td>\n",
       "      <td>subhas patel</td>\n",
       "      <td>Technical Training, Software Development, Pres...</td>\n",
       "      <td>Indore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LibraryXProject</td>\n",
       "      <td>Human Resource</td>\n",
       "      <td>LibraryXProject</td>\n",
       "      <td>Software Development, It Sales, Account Manage...</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Name                  Designation  \\\n",
       "0                           Aakash Harit                   HR Manager   \n",
       "1                   Data Science Network            Company Recruiter   \n",
       "2                   shravan Kumar Gaddam                   Company HR   \n",
       "3          Shore Infotech India Pvt. Ltd            Company Recruiter   \n",
       "4               MARSIAN Technologies LLP                  Founder CEO   \n",
       "5               MARSIAN Technologies LLP  Recruitment Lead Consultant   \n",
       "6                           Anik Agrawal            Programme Manager   \n",
       "7  Enerlytics Software Solutions Pvt Ltd             HR Administrator   \n",
       "8                           subhas patel                     Director   \n",
       "9                        LibraryXProject               Human Resource   \n",
       "\n",
       "                                 Company  \\\n",
       "0                           Aakash Harit   \n",
       "1                   Data Science Network   \n",
       "2                   shravan Kumar Gaddam   \n",
       "3          Shore Infotech India Pvt. Ltd   \n",
       "4               MARSIAN Technologies LLP   \n",
       "5               MARSIAN Technologies LLP   \n",
       "6                           Anik Agrawal   \n",
       "7  Enerlytics Software Solutions Pvt Ltd   \n",
       "8                           subhas patel   \n",
       "9                        LibraryXProject   \n",
       "\n",
       "                                Skills_they_hire_for                  Location  \n",
       "0  Classic ASP Developer, Internet Marketing Prof...                     Delhi  \n",
       "1  .Net, Java, Data Science, Linux Administration...  Hyderabad / Secunderabad  \n",
       "2  Data Science, Artificial Intelligence, Machine...                      Pune  \n",
       "3  Mean Stack, javascript, angularjs, mongodb, We...                 Ahmedabad  \n",
       "4  Hadoop, Spark, Digital Strategy, Data Architec...             UK - (london)  \n",
       "5  Analytics, Business Intelligence, Business Ana...         Vadodara / Baroda  \n",
       "6                                       Data Science                   Chennai  \n",
       "7  Machine Learning, algorithms, Go Getter, Compu...                Trivandrum  \n",
       "8  Technical Training, Software Development, Pres...                    Indore  \n",
       "9  Software Development, It Sales, Account Manage...     Bengaluru / Bangalore  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({\"Name\":Name,\"Designation\":Designation,\"Company\":Company,\"Skills_they_hire_for\":Skills_they_hire_for,\"Location\":Location})\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "815f0cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5a540e",
   "metadata": {},
   "source": [
    "# 8. Scrape the details of Highest selling novels.\n",
    "Url = https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey\u0002compare/\n",
    "You have to find the following details:\n",
    "A) Book name\n",
    "B) Author name\n",
    "C) Volumes sold\n",
    "D) Publisher\n",
    "E) Genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d7313d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#connecting to the web driver\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\princ\\Downloads\\chromedriver_win32 (3)\\chromedriver.exe\") \n",
    "\n",
    "#get the url\n",
    "url = \"https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare/\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c8fba8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating empty lists for scraping data\n",
    "Book_name=[]\n",
    "Author_name=[]\n",
    "Volumes_sold=[]\n",
    "Publisher=[]\n",
    "Genre=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bd5a6ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping Books Name\n",
    "book=driver.find_elements(By.XPATH,\"//td[@class='left']\")\n",
    "for i in book:\n",
    "    if i.text is None :\n",
    "        Book_name.append(\"--\") \n",
    "    else:\n",
    "        Book_name.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "269f221c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping Author name\n",
    "author=driver.find_elements(By.XPATH,\"//td[@class='left']\")\n",
    "for i in author:\n",
    "    if i.text is None :\n",
    "        Author_name.append(\"--\") \n",
    "    else:\n",
    "        Author_name.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fb50ce13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping Volumes Sold\n",
    "volume=driver.find_elements(By.XPATH,\"//td[@class='left']\")\n",
    "for i in volume:\n",
    "    if i.text is None :\n",
    "        Volumes_sold.append(\"--\") \n",
    "    else:\n",
    "        Volumes_sold.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e85888ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping Publisher\n",
    "publisher=driver.find_elements(By.XPATH,\"//td[@class='left']\")\n",
    "for i in publisher:\n",
    "    if i.text is None :\n",
    "        Publisher.append(\"--\") \n",
    "    else:\n",
    "        Publisher.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "13a373e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping Genre\n",
    "genre = driver.find_elements(By.XPATH,\"//td[@class='last left']\")\n",
    "for i in genre:\n",
    "    if i.text is None :\n",
    "        Genre.append(\"--\")\n",
    "    else:\n",
    "        Genre.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ef9c629b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book_name</th>\n",
       "      <th>Author_name</th>\n",
       "      <th>Volumes_sold</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Da Vinci Code,The</td>\n",
       "      <td>Brown, Dan</td>\n",
       "      <td>5,094,805</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry Potter and the Deathly Hallows</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,475,152</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,200,654</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,179,479</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fifty Shades of Grey</td>\n",
       "      <td>James, E. L.</td>\n",
       "      <td>3,758,936</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Romance &amp; Sagas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Ghost,The</td>\n",
       "      <td>Harris, Robert</td>\n",
       "      <td>807,311</td>\n",
       "      <td>Random House</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Happy Days with the Naked Chef</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>794,201</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Hunger Games,The:Hunger Games Trilogy</td>\n",
       "      <td>Collins, Suzanne</td>\n",
       "      <td>792,187</td>\n",
       "      <td>Scholastic Ltd.</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Lost Boy,The:A Foster Child's Search for the L...</td>\n",
       "      <td>Pelzer, Dave</td>\n",
       "      <td>791,507</td>\n",
       "      <td>Orion</td>\n",
       "      <td>Biography: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Jamie's Ministry of Food:Anyone Can Learn to C...</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>791,095</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Book_name       Author_name  \\\n",
       "0                                   Da Vinci Code,The        Brown, Dan   \n",
       "1                Harry Potter and the Deathly Hallows     Rowling, J.K.   \n",
       "2            Harry Potter and the Philosopher's Stone     Rowling, J.K.   \n",
       "3           Harry Potter and the Order of the Phoenix     Rowling, J.K.   \n",
       "4                                Fifty Shades of Grey      James, E. L.   \n",
       "..                                                ...               ...   \n",
       "95                                          Ghost,The    Harris, Robert   \n",
       "96                     Happy Days with the Naked Chef     Oliver, Jamie   \n",
       "97              Hunger Games,The:Hunger Games Trilogy  Collins, Suzanne   \n",
       "98  Lost Boy,The:A Foster Child's Search for the L...      Pelzer, Dave   \n",
       "99  Jamie's Ministry of Food:Anyone Can Learn to C...     Oliver, Jamie   \n",
       "\n",
       "   Volumes_sold        Publisher                        Genre  \n",
       "0     5,094,805       Transworld  Crime, Thriller & Adventure  \n",
       "1     4,475,152       Bloomsbury           Children's Fiction  \n",
       "2     4,200,654       Bloomsbury           Children's Fiction  \n",
       "3     4,179,479       Bloomsbury           Children's Fiction  \n",
       "4     3,758,936     Random House              Romance & Sagas  \n",
       "..          ...              ...                          ...  \n",
       "95      807,311     Random House   General & Literary Fiction  \n",
       "96      794,201          Penguin        Food & Drink: General  \n",
       "97      792,187  Scholastic Ltd.          Young Adult Fiction  \n",
       "98      791,507            Orion           Biography: General  \n",
       "99      791,095          Penguin        Food & Drink: General  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating the dataframe from the scraped data\n",
    "df=pd.DataFrame({\"Book_name\":Book_name[1::5],\"Author_name\":Author_name[2::5],\"Volumes_sold\":Volumes_sold[3::5],\"Publisher\":Publisher[4::5],\"Genre\":Genre})\n",
    "df  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b0c4c9",
   "metadata": {},
   "source": [
    "# 9. Scrape the details most watched tv series of all time from imdb.com.\n",
    "Url = https://www.imdb.com/list/ls095964455/\n",
    "You have to find the following details:\n",
    "A) Name\n",
    "B) Year span\n",
    "C) Genre\n",
    "D) Run time\n",
    "E) Ratings\n",
    "F) Votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bc5c3c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#connecting to the web driver\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\princ\\Downloads\\chromedriver_win32 (3)\\chromedriver.exe\") \n",
    "\n",
    "#get the url\n",
    "url = \"https://www.imdb.com/list/ls095964455/\"\n",
    "driver.get(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "16ebf944",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating empty lists for scraping data\n",
    "Name=[]\n",
    "Year_span=[]\n",
    "Genre=[]\n",
    "Run_time=[]\n",
    "Ratings=[]\n",
    "Votes=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9e64b0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping top Movies name\n",
    "name = driver.find_elements(By.XPATH,\"//h3[@class='lister-item-header']//a\")\n",
    "for i in name:       \n",
    "    if i.text is None :\n",
    "        Name.append(\"--\") \n",
    "    else:\n",
    "        Name.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "87214bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping year span       \n",
    "year = driver.find_elements(By.XPATH,\"//span[@class='lister-item-year text-muted unbold']\")\n",
    "for i in year:       \n",
    "    if i.text is None :\n",
    "        Year_span.append(\"--\") \n",
    "    else:\n",
    "        Year_span.append(i.text) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "321eb5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping genre       \n",
    "gen = driver.find_elements(By.XPATH,\"//span[@class='genre']\")\n",
    "for i in gen :       \n",
    "    if i.text is None :\n",
    "        Genre.append(\"--\") \n",
    "    else:\n",
    "        Genre.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d49e6c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping run time\n",
    "time = driver.find_elements(By.XPATH,\"//span[@class='runtime']\")\n",
    "for i in time:       \n",
    "    if i.text is None :\n",
    "        Run_time.append(\"--\") \n",
    "    else:\n",
    "        Run_time.append(i.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4948e386",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping ratings\n",
    "rate = driver.find_elements(By.XPATH,\"//div[@class='ipl-rating-star small']\")\n",
    "for i in rate:       \n",
    "    if i.text is None :\n",
    "        Ratings.append(\"--\") \n",
    "    else:\n",
    "        Ratings.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "077bad72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping votes\n",
    "vote = driver.find_elements(By.XPATH,\"//span[@name='nv']\")\n",
    "for i in vote:       \n",
    "    if i.text is None :\n",
    "        Votes.append(\"--\") \n",
    "    else:\n",
    "        Votes.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "53938ee7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Year_span</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Run_time</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Game of Thrones</td>\n",
       "      <td>(2011–2019)</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>57 min</td>\n",
       "      <td>9.2</td>\n",
       "      <td>2,062,615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stranger Things</td>\n",
       "      <td>(2016– )</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "      <td>51 min</td>\n",
       "      <td>8.7</td>\n",
       "      <td>1,155,967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Walking Dead</td>\n",
       "      <td>(2010–2022)</td>\n",
       "      <td>Drama, Horror, Thriller</td>\n",
       "      <td>44 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>972,841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13 Reasons Why</td>\n",
       "      <td>(2017–2020)</td>\n",
       "      <td>Drama, Mystery, Thriller</td>\n",
       "      <td>60 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>290,021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The 100</td>\n",
       "      <td>(2014–2020)</td>\n",
       "      <td>Drama, Mystery, Sci-Fi</td>\n",
       "      <td>43 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>249,407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Reign</td>\n",
       "      <td>(2013–2017)</td>\n",
       "      <td>Drama</td>\n",
       "      <td>42 min</td>\n",
       "      <td>7.4</td>\n",
       "      <td>49,706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>A Series of Unfortunate Events</td>\n",
       "      <td>(2017–2019)</td>\n",
       "      <td>Adventure, Comedy, Drama</td>\n",
       "      <td>50 min</td>\n",
       "      <td>7.8</td>\n",
       "      <td>60,773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Criminal Minds</td>\n",
       "      <td>(2005–2020)</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>42 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>195,611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Scream: The TV Series</td>\n",
       "      <td>(2015–2019)</td>\n",
       "      <td>Comedy, Crime, Drama</td>\n",
       "      <td>45 min</td>\n",
       "      <td>7.1</td>\n",
       "      <td>41,163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>The Haunting of Hill House</td>\n",
       "      <td>(2018)</td>\n",
       "      <td>Drama, Horror, Mystery</td>\n",
       "      <td>572 min</td>\n",
       "      <td>8.6</td>\n",
       "      <td>238,356</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Name    Year_span                     Genre  \\\n",
       "0                  Game of Thrones  (2011–2019)  Action, Adventure, Drama   \n",
       "1                  Stranger Things     (2016– )    Drama, Fantasy, Horror   \n",
       "2                 The Walking Dead  (2010–2022)   Drama, Horror, Thriller   \n",
       "3                   13 Reasons Why  (2017–2020)  Drama, Mystery, Thriller   \n",
       "4                          The 100  (2014–2020)    Drama, Mystery, Sci-Fi   \n",
       "..                             ...          ...                       ...   \n",
       "95                           Reign  (2013–2017)                     Drama   \n",
       "96  A Series of Unfortunate Events  (2017–2019)  Adventure, Comedy, Drama   \n",
       "97                  Criminal Minds  (2005–2020)     Crime, Drama, Mystery   \n",
       "98           Scream: The TV Series  (2015–2019)      Comedy, Crime, Drama   \n",
       "99      The Haunting of Hill House       (2018)    Drama, Horror, Mystery   \n",
       "\n",
       "   Run_time Ratings      Votes  \n",
       "0    57 min     9.2  2,062,615  \n",
       "1    51 min     8.7  1,155,967  \n",
       "2    44 min     8.1    972,841  \n",
       "3    60 min     7.5    290,021  \n",
       "4    43 min     7.6    249,407  \n",
       "..      ...     ...        ...  \n",
       "95   42 min     7.4     49,706  \n",
       "96   50 min     7.8     60,773  \n",
       "97   42 min     8.1    195,611  \n",
       "98   45 min     7.1     41,163  \n",
       "99  572 min     8.6    238,356  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating the dataframe from the scraped data\n",
    "df=pd.DataFrame({\"Name\":Name,\"Year_span\":Year_span,\"Genre\":Genre,\"Run_time\":Run_time,\"Ratings\":Ratings,\"Votes\":Votes})\n",
    "df "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ed7658",
   "metadata": {},
   "source": [
    "# 10. Details of Datasets from UCI machine learning repositories.\n",
    "Url = https://archive.ics.uci.edu/\n",
    "You have to find the following details:\n",
    "A) Dataset name\n",
    "B) Data type\n",
    "C) Task\n",
    "D) Attribute type\n",
    "E) No of instances\n",
    "F) No of attribute\n",
    "G) Year\n",
    "Note: - from the home page you have to go to the ShowAllDataset page through code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0085441a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#connecting to the web driver\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\princ\\Downloads\\chromedriver_win32 (3)\\chromedriver.exe\") \n",
    "\n",
    "#get the url\n",
    "url = \"https://archive.ics.uci.edu/\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ed1dafd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicking the 'View all dataset'\n",
    "view_dataset=driver.find_element(By.XPATH,\"/html/body/table[1]/tbody/tr/td[2]/span[2]/a/font/b\")\n",
    "view_dataset.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "eb431b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating empty list for scraping data\n",
    "Dataset_name=[]\n",
    "Data_type=[]\n",
    "Task=[]\n",
    "Attribute_type=[]\n",
    "No_of_instances=[]\n",
    "No_of_attribute=[]\n",
    "Year=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "248063b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping Dataset_name\n",
    "dataset = driver.find_elements(By.XPATH,\"//p[@class='normal']//b\")\n",
    "for i in dataset:       \n",
    "    if i.text is None :\n",
    "        Dataset_name.append(\"--\") \n",
    "    else:\n",
    "        Dataset_name.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "43aa6e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping Data_type\n",
    "datatype = driver.find_elements(By.XPATH,\"//p[@class='normal']\")[:4125]\n",
    "for i in datatype:       \n",
    "    if i.text is None :\n",
    "        Data_type.append(\"--\") \n",
    "    else:\n",
    "        Data_type.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cff3a379",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping Task\n",
    "task = driver.find_elements(By.XPATH,\"//p[@class='normal']\")\n",
    "for i in task:       \n",
    "    if i.text is None :\n",
    "        Task.append(\"--\") \n",
    "    else:\n",
    "        Task.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f3850254",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping Attribute_type\n",
    "attribute_type = driver.find_elements(By.XPATH,\"//p[@class='normal']\")\n",
    "for i in attribute_type:       \n",
    "    if i.text is None :\n",
    "        Attribute_type.append(\"--\") \n",
    "    else:\n",
    "        Attribute_type.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "63df5631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping No_of_instances\n",
    "instances = driver.find_elements(By.XPATH,\"//p[@class='normal']\")\n",
    "for i in instances:       \n",
    "    if i.text is None :\n",
    "        No_of_instances.append(\"--\") \n",
    "    else:\n",
    "        No_of_instances.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "20a5bda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping No_of_attribute\n",
    "attribute = driver.find_elements(By.XPATH,\"//p[@class='normal']\")\n",
    "for i in attribute:\n",
    "    if i.text is None :\n",
    "        No_of_attribute.append(\"--\") \n",
    "    else:\n",
    "        No_of_attribute.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a1e02005",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_2836/611976932.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# creating the dataframe from the scraped data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m df=pd.DataFrame({\"Dataset_name\":Dataset_name,\n\u001b[0m\u001b[0;32m      3\u001b[0m                  \u001b[1;34m\"Data_type\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mData_type\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                  \u001b[1;34m\"Task\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mTask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                  \u001b[1;34m\"Attribute_type\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mAttribute_type\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    612\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    613\u001b[0m             \u001b[1;31m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 614\u001b[1;33m             \u001b[0mmgr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict_to_mgr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtyp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmanager\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    615\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    616\u001b[0m             \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    462\u001b[0m         \u001b[1;31m# TODO: can we get rid of the dt64tz special case above?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 464\u001b[1;33m     return arrays_to_mgr(\n\u001b[0m\u001b[0;32m    465\u001b[0m         \u001b[0marrays\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtyp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtyp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconsolidate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    466\u001b[0m     )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, arr_names, index, columns, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    117\u001b[0m         \u001b[1;31m# figure out the index, if necessary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 119\u001b[1;33m             \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_extract_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    120\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m             \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36m_extract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    633\u001b[0m             \u001b[0mlengths\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_lengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 635\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"All arrays must be of the same length\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    637\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhave_dicts\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "# creating the dataframe from the scraped data\n",
    "df=pd.DataFrame({\"Dataset_name\":Dataset_name,\n",
    "                 \"Data_type\":Data_type,\n",
    "                 \"Task\":Task,\n",
    "                 \"Attribute_type\":Attribute_type,\n",
    "                 \"No_of_instances\":No_of_instances,\n",
    "                 \"No_of_attribute\":No_of_attribute})\n",
    "df         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0312f43a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
